---
title: "Measuring Interaction Proxemics with Wearable Light Tags"

# Authors
# If you created a profile for a user (e.g. the default `admin` user), write the username (folder name) here 
# and it will be replaced with their full name and linked to their profile.
authors:
- Alessandro Montanari 
- Zhao Tian 
- Elena Francu 
- Benjamin Lucas 
- Brian Jones 
- admin
- Cecilia Mascolo

# Author notes (optional)
# author_notes:
# - "Equal contribution"
# - "Equal contribution"

date: "2018-03-01T00:00:00Z"
doi: ""

# Schedule page publish date (NOT publication's date).
publishDate: "2018-03-01T00:00:00Z"

# Publication type.
# Legend: 0 = Uncategorized; 1 = Conference paper; 2 = Journal article;
# 3 = Preprint / Working Paper; 4 = Report; 5 = Book; 6 = Book section;
# 7 = Thesis; 8 = Patent
publication_types: ["1"]

# Publication name and optional abbreviated publication name.
publication: Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies(IMWUT), Vol. 2, No. 1, 2018.
publication_short: IMWUT
award: ""

abstract: "The proxemics of social interactions (e.g., body distance, relative orientation) influences many aspects of our everyday life: from patients' reactions to interaction with physicians, successes in job interviews, to effective teamwork. Traditionally, interaction proxemics has been studied via questionnaires and participant observations, imposing high burden on users, low scalability and precision, and often biases.

In this paper we present Protractor, a novel wearable technology for measuring interaction proxemics as part of non-verbal behavior cues with fine granularity. Protractor employs near-infrared light to monitor both the distance and relative body orientation of interacting users. We leverage the characteristics of near-infrared light (i.e., line-of-sight propagation) to accurately and reliably identify interactions; a pair of collocated photodiodes aid the inference of relative interaction angle and distance. We achieve robustness against temporary blockage of the light channel (e.g., by the user's hand or clothes) by designing sensor fusion algorithms that exploit inertial sensors to obviate the absence of light tracking results.

We fabricated Protractor tags and conducted real-world experiments. Results show its accuracy in tracking body distances and relative angles. The framework achieves less than 6Â° error 95% of the time for measuring relative body orientation and 2.3-cm - 4.9-cm mean error in estimating interaction distance. We deployed Protractor tags to track user's non-verbal behaviors when conducting collaborative group tasks. Results with 64 participants show that distance and angle data from Protractor tags can help assess individual's task role with 84.9% accuracy, and identify task timeline with 93.2% accuracy."

# Summary. An optional shortened abstract.
summary: ""

tags: []

# Display this page in the Featured widget?
featured: false

# do not open its dedicated page
nopage: true

# Custom links (uncomment lines below)
url_pdf: ''
url_code: ''
url_dataset: ''
url_poster: ''
url_project: ''
url_slides: ''
url_source: ''
url_video: ''

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder. 
image:
  caption: ''
  focal_point: ""
  preview_only: false

# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `internal-project` references `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
projects: false

# Slides (optional).
#   Associate this publication with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides: "example"` references `content/slides/example/index.md`.
#   Otherwise, set `slides: ""`.
slides: false
---

