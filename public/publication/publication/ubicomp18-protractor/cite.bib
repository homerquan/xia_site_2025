@article{10.1145/3191757,
author = {Montanari, Alessandro and Tian, Zhao and Francu, Elena and Lucas, Benjamin and Jones, Brian and Zhou, Xia and Mascolo, Cecilia},
title = {Measuring Interaction Proxemics with Wearable Light Tags},
year = {2018},
issue_date = {March 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {1},
url = {https://doi.org/10.1145/3191757},
doi = {10.1145/3191757},
abstract = {The proxemics of social interactions (e.g., body distance, relative orientation) influences many aspects of our everyday life: from patients' reactions to interaction with physicians, successes in job interviews, to effective teamwork. Traditionally, interaction proxemics has been studied via questionnaires and participant observations, imposing high burden on users, low scalability and precision, and often biases.In this paper we present Protractor, a novel wearable technology for measuring interaction proxemics as part of non-verbal behavior cues with fine granularity. Protractor employs near-infrared light to monitor both the distance and relative body orientation of interacting users. We leverage the characteristics of near-infrared light (i.e., line-of-sight propagation) to accurately and reliably identify interactions; a pair of collocated photodiodes aid the inference of relative interaction angle and distance. We achieve robustness against temporary blockage of the light channel (e.g., by the user's hand or clothes) by designing sensor fusion algorithms that exploit inertial sensors to obviate the absence of light tracking results.We fabricated Protractor tags and conducted real-world experiments. Results show its accuracy in tracking body distances and relative angles. The framework achieves less than 6Â° error 95% of the time for measuring relative body orientation and 2.3-cm - 4.9-cm mean error in estimating interaction distance. We deployed Protractor tags to track user's non-verbal behaviors when conducting collaborative group tasks. Results with 64 participants show that distance and angle data from Protractor tags can help assess individual's task role with 84.9% accuracy, and identify task timeline with 93.2% accuracy.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = mar,
articleno = {25},
numpages = {30},
keywords = {non-verbal behaviors, light sensing, Face-to-face interactions}
}